# æç»†è‡´æ€§èƒ½å‰–æå·¥å…·

> **ğŸ”¥ çº³ç§’çº§ç²¾åº¦åˆ†æ**ï¼šæ„å»ºä¸“ä¸šçº§JVMåˆå§‹åŒ–æ€§èƒ½å‰–æå·¥å…·ï¼Œæä¾›å¾®ç§’çº§æ—¶åºåˆ†æã€å†…å­˜åˆ†é…è¿½è¸ªã€ç³»ç»Ÿè°ƒç”¨ç›‘æ§ã€CPUæ€§èƒ½è®¡æ•°å™¨é›†æˆçš„å®Œæ•´è§£å†³æ–¹æ¡ˆ

---

## ğŸ¯ é«˜ç²¾åº¦æ—¶åºåˆ†æå·¥å…·

### ğŸ’» çº³ç§’çº§æ—¶é—´æˆ³æ”¶é›†å™¨

```python
#!/usr/bin/env python3
# ğŸ”¥ JVMåˆå§‹åŒ–çº³ç§’çº§æ€§èƒ½åˆ†æå·¥å…·
# æ–‡ä»¶ï¼šultra_precise_jvm_profiler.py

import os
import sys
import time
import json
import ctypes
import subprocess
import threading
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional, Tuple
from collections import defaultdict
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

@dataclass
class TimestampEvent:
    """æ—¶é—´æˆ³äº‹ä»¶æ•°æ®ç»“æ„"""
    timestamp_ns: int           # çº³ç§’æ—¶é—´æˆ³
    event_type: str            # äº‹ä»¶ç±»å‹
    event_name: str            # äº‹ä»¶åç§°
    thread_id: int             # çº¿ç¨‹ID
    cpu_id: int                # CPUæ ¸å¿ƒID
    memory_usage: int          # å†…å­˜ä½¿ç”¨é‡
    additional_data: Dict      # é™„åŠ æ•°æ®

class HighPrecisionTimer:
    """é«˜ç²¾åº¦è®¡æ—¶å™¨"""
    
    def __init__(self):
        # ğŸ”¥ åŠ è½½é«˜ç²¾åº¦æ—¶é—´å‡½æ•°
        self.libc = ctypes.CDLL("libc.so.6")
        self.clock_gettime = self.libc.clock_gettime
        self.clock_gettime.argtypes = [ctypes.c_int, ctypes.POINTER(ctypes.c_long * 2)]
        
        # ğŸ”¥ æ—¶é’Ÿç±»å‹å¸¸é‡
        self.CLOCK_MONOTONIC = 1
        self.CLOCK_PROCESS_CPUTIME_ID = 2
        self.CLOCK_THREAD_CPUTIME_ID = 3
        
        # ğŸ”¥ æ ¡å‡†è®¡æ—¶å™¨å¼€é”€
        self.timer_overhead_ns = self._calibrate_timer_overhead()
    
    def get_monotonic_time_ns(self) -> int:
        """è·å–å•è°ƒæ—¶é—´ï¼ˆçº³ç§’ï¼‰"""
        timespec = (ctypes.c_long * 2)()
        self.clock_gettime(self.CLOCK_MONOTONIC, timespec)
        return timespec[0] * 1_000_000_000 + timespec[1] - self.timer_overhead_ns
    
    def get_process_cpu_time_ns(self) -> int:
        """è·å–è¿›ç¨‹CPUæ—¶é—´ï¼ˆçº³ç§’ï¼‰"""
        timespec = (ctypes.c_long * 2)()
        self.clock_gettime(self.CLOCK_PROCESS_CPUTIME_ID, timespec)
        return timespec[0] * 1_000_000_000 + timespec[1]
    
    def get_thread_cpu_time_ns(self) -> int:
        """è·å–çº¿ç¨‹CPUæ—¶é—´ï¼ˆçº³ç§’ï¼‰"""
        timespec = (ctypes.c_long * 2)()
        self.clock_gettime(self.CLOCK_THREAD_CPUTIME_ID, timespec)
        return timespec[0] * 1_000_000_000 + timespec[1]
    
    def _calibrate_timer_overhead(self) -> int:
        """æ ¡å‡†è®¡æ—¶å™¨è°ƒç”¨å¼€é”€"""
        measurements = []
        for _ in range(1000):
            start = time.perf_counter_ns()
            time.perf_counter_ns()
            end = time.perf_counter_ns()
            measurements.append(end - start)
        
        # ğŸ”¥ ä½¿ç”¨æœ€å°å€¼ä½œä¸ºå¼€é”€ä¼°è®¡
        return min(measurements)

class JVMInitProfiler:
    """JVMåˆå§‹åŒ–æ€§èƒ½å‰–æå™¨"""
    
    def __init__(self, jvm_args: List[str], main_class: str):
        self.jvm_args = jvm_args
        self.main_class = main_class
        self.timer = HighPrecisionTimer()
        self.events: List[TimestampEvent] = []
        self.start_time_ns = 0
        self.jvm_process = None
        
        # ğŸ”¥ æ€§èƒ½è®¡æ•°å™¨
        self.perf_counters = PerfCounterCollector()
        
        # ğŸ”¥ å†…å­˜ç›‘æ§å™¨
        self.memory_monitor = MemoryMonitor()
        
        # ğŸ”¥ ç³»ç»Ÿè°ƒç”¨è¿½è¸ªå™¨
        self.syscall_tracer = SystemCallTracer()
    
    def profile_jvm_initialization(self) -> Dict:
        """æ‰§è¡Œå®Œæ•´çš„JVMåˆå§‹åŒ–æ€§èƒ½å‰–æ"""
        
        print("ğŸš€ å¼€å§‹JVMåˆå§‹åŒ–æ€§èƒ½å‰–æ...")
        
        # ğŸ”¥ ç¬¬1é˜¶æ®µï¼šé¢„å¯åŠ¨å‡†å¤‡
        self._record_event("pre_startup", "preparation_start")
        self._prepare_profiling_environment()
        self._record_event("pre_startup", "preparation_complete")
        
        # ğŸ”¥ ç¬¬2é˜¶æ®µï¼šå¯åŠ¨JVMè¿›ç¨‹
        self._record_event("jvm_startup", "process_creation_start")
        self._start_jvm_process()
        self._record_event("jvm_startup", "process_creation_complete")
        
        # ğŸ”¥ ç¬¬3é˜¶æ®µï¼šç›‘æ§åˆå§‹åŒ–è¿‡ç¨‹
        self._record_event("initialization", "monitoring_start")
        init_data = self._monitor_initialization_process()
        self._record_event("initialization", "monitoring_complete")
        
        # ğŸ”¥ ç¬¬4é˜¶æ®µï¼šæ”¶é›†æœ€ç»ˆæ•°æ®
        self._record_event("post_analysis", "data_collection_start")
        final_data = self._collect_final_performance_data()
        self._record_event("post_analysis", "data_collection_complete")
        
        # ğŸ”¥ ç¬¬5é˜¶æ®µï¼šç”Ÿæˆåˆ†ææŠ¥å‘Š
        self._record_event("reporting", "analysis_start")
        report = self._generate_comprehensive_report(init_data, final_data)
        self._record_event("reporting", "analysis_complete")
        
        return report
    
    def _prepare_profiling_environment(self):
        """å‡†å¤‡æ€§èƒ½å‰–æç¯å¢ƒ"""
        
        # ğŸ”¥ è®¾ç½®CPUäº²å’Œæ€§ï¼ˆç»‘å®šåˆ°ç‰¹å®šæ ¸å¿ƒï¼‰
        os.sched_setaffinity(0, {0})  # ç»‘å®šåˆ°CPUæ ¸å¿ƒ0
        
        # ğŸ”¥ è®¾ç½®è¿›ç¨‹ä¼˜å…ˆçº§
        os.nice(-10)  # æé«˜ä¼˜å…ˆçº§
        
        # ğŸ”¥ ç¦ç”¨CPUé¢‘ç‡ç¼©æ”¾
        self._disable_cpu_frequency_scaling()
        
        # ğŸ”¥ æ¸…ç†ç³»ç»Ÿç¼“å­˜
        self._clear_system_caches()
        
        # ğŸ”¥ å¯åŠ¨æ€§èƒ½è®¡æ•°å™¨æ”¶é›†
        self.perf_counters.start_collection()
        
        # ğŸ”¥ å¯åŠ¨å†…å­˜ç›‘æ§
        self.memory_monitor.start_monitoring()
    
    def _start_jvm_process(self):
        """å¯åŠ¨JVMè¿›ç¨‹å¹¶å¼€å§‹ç›‘æ§"""
        
        # ğŸ”¥ æ„å»ºå®Œæ•´çš„JVMå‘½ä»¤
        jvm_cmd = ['java'] + self.jvm_args + [
            '-XX:+UnlockDiagnosticVMOptions',
            '-XX:+TraceStartupTime',
            '-XX:+PrintGCTimeStamps',
            '-XX:+PrintGCDetails',
            '-XX:+LogVMOutput',
            '-XX:LogFile=jvm_startup.log',
            self.main_class
        ]
        
        # ğŸ”¥ è®°å½•å¯åŠ¨æ—¶é—´æˆ³
        self.start_time_ns = self.timer.get_monotonic_time_ns()
        
        # ğŸ”¥ å¯åŠ¨JVMè¿›ç¨‹
        self.jvm_process = subprocess.Popen(
            jvm_cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            preexec_fn=lambda: os.sched_setaffinity(0, {1})  # JVMç»‘å®šåˆ°CPUæ ¸å¿ƒ1
        )
        
        # ğŸ”¥ å¯åŠ¨ç³»ç»Ÿè°ƒç”¨è¿½è¸ª
        self.syscall_tracer.start_tracing(self.jvm_process.pid)
    
    def _monitor_initialization_process(self) -> Dict:
        """ç›‘æ§JVMåˆå§‹åŒ–è¿‡ç¨‹"""
        
        init_phases = {
            'vm_init_globals': {'start': None, 'end': None, 'duration_ns': 0},
            'init_globals': {'start': None, 'end': None, 'duration_ns': 0},
            'universe_init': {'start': None, 'end': None, 'duration_ns': 0},
            'interpreter_init': {'start': None, 'end': None, 'duration_ns': 0},
            'compiler_init': {'start': None, 'end': None, 'duration_ns': 0}
        }
        
        # ğŸ”¥ è§£æJVMå¯åŠ¨æ—¥å¿—
        log_parser = JVMLogParser()
        
        # ğŸ”¥ å®æ—¶ç›‘æ§JVMè¿›ç¨‹
        monitoring_thread = threading.Thread(
            target=self._real_time_monitoring,
            args=(init_phases,)
        )
        monitoring_thread.start()
        
        # ğŸ”¥ ç­‰å¾…JVMåˆå§‹åŒ–å®Œæˆ
        stdout, stderr = self.jvm_process.communicate(timeout=60)
        
        # ğŸ”¥ åœæ­¢ç›‘æ§
        monitoring_thread.join(timeout=5)
        
        # ğŸ”¥ è§£æå¯åŠ¨æ—¥å¿—
        startup_events = log_parser.parse_startup_log('jvm_startup.log')
        
        # ğŸ”¥ åˆå¹¶ç›‘æ§æ•°æ®
        return {
            'init_phases': init_phases,
            'startup_events': startup_events,
            'stdout': stdout.decode('utf-8'),
            'stderr': stderr.decode('utf-8'),
            'exit_code': self.jvm_process.returncode
        }
    
    def _real_time_monitoring(self, init_phases: Dict):
        """å®æ—¶ç›‘æ§JVMè¿›ç¨‹çŠ¶æ€"""
        
        pid = self.jvm_process.pid
        
        while self.jvm_process.poll() is None:
            current_time = self.timer.get_monotonic_time_ns()
            
            # ğŸ”¥ æ”¶é›†è¿›ç¨‹çŠ¶æ€
            try:
                with open(f'/proc/{pid}/stat', 'r') as f:
                    stat_data = f.read().split()
                
                # ğŸ”¥ è§£æè¿›ç¨‹çŠ¶æ€
                process_state = {
                    'timestamp_ns': current_time,
                    'pid': int(stat_data[0]),
                    'state': stat_data[2],
                    'utime': int(stat_data[13]),  # ç”¨æˆ·æ€æ—¶é—´
                    'stime': int(stat_data[14]),  # å†…æ ¸æ€æ—¶é—´
                    'vsize': int(stat_data[22]),  # è™šæ‹Ÿå†…å­˜å¤§å°
                    'rss': int(stat_data[23]),    # ç‰©ç†å†…å­˜å¤§å°
                }
                
                # ğŸ”¥ è®°å½•è¿›ç¨‹çŠ¶æ€äº‹ä»¶
                self._record_event(
                    "process_monitoring",
                    "process_state",
                    additional_data=process_state
                )
                
            except (FileNotFoundError, ValueError, IndexError):
                # è¿›ç¨‹å¯èƒ½å·²ç»ç»“æŸ
                break
            
            # ğŸ”¥ 100å¾®ç§’é‡‡æ ·é—´éš”
            time.sleep(0.0001)
    
    def _record_event(self, event_type: str, event_name: str, 
                     additional_data: Optional[Dict] = None):
        """è®°å½•æ—¶é—´æˆ³äº‹ä»¶"""
        
        event = TimestampEvent(
            timestamp_ns=self.timer.get_monotonic_time_ns(),
            event_type=event_type,
            event_name=event_name,
            thread_id=threading.get_ident(),
            cpu_id=os.sched_getaffinity(0).pop(),
            memory_usage=self._get_current_memory_usage(),
            additional_data=additional_data or {}
        )
        
        self.events.append(event)
    
    def _get_current_memory_usage(self) -> int:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡"""
        try:
            with open('/proc/self/status', 'r') as f:
                for line in f:
                    if line.startswith('VmRSS:'):
                        return int(line.split()[1]) * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
        except:
            return 0
        return 0

class PerfCounterCollector:
    """æ€§èƒ½è®¡æ•°å™¨æ”¶é›†å™¨"""
    
    def __init__(self):
        self.perf_process = None
        self.counter_data = []
    
    def start_collection(self):
        """å¼€å§‹æ”¶é›†æ€§èƒ½è®¡æ•°å™¨"""
        
        # ğŸ”¥ å®šä¹‰è¦æ”¶é›†çš„æ€§èƒ½è®¡æ•°å™¨
        perf_events = [
            'cycles',                    # CPUå‘¨æœŸ
            'instructions',              # æŒ‡ä»¤æ•°
            'cache-references',          # ç¼“å­˜å¼•ç”¨
            'cache-misses',             # ç¼“å­˜æœªå‘½ä¸­
            'branch-instructions',       # åˆ†æ”¯æŒ‡ä»¤
            'branch-misses',            # åˆ†æ”¯é¢„æµ‹é”™è¯¯
            'L1-dcache-loads',          # L1æ•°æ®ç¼“å­˜åŠ è½½
            'L1-dcache-load-misses',    # L1æ•°æ®ç¼“å­˜æœªå‘½ä¸­
            'L1-icache-load-misses',    # L1æŒ‡ä»¤ç¼“å­˜æœªå‘½ä¸­
            'LLC-loads',                # æœ€åçº§ç¼“å­˜åŠ è½½
            'LLC-load-misses',          # æœ€åçº§ç¼“å­˜æœªå‘½ä¸­
            'dTLB-loads',               # æ•°æ®TLBåŠ è½½
            'dTLB-load-misses',         # æ•°æ®TLBæœªå‘½ä¸­
            'iTLB-loads',               # æŒ‡ä»¤TLBåŠ è½½
            'iTLB-load-misses',         # æŒ‡ä»¤TLBæœªå‘½ä¸­
            'page-faults',              # é¡µé¢é”™è¯¯
            'context-switches',         # ä¸Šä¸‹æ–‡åˆ‡æ¢
            'cpu-migrations',           # CPUè¿ç§»
        ]
        
        # ğŸ”¥ æ„å»ºperfå‘½ä»¤
        perf_cmd = [
            'perf', 'stat',
            '-e', ','.join(perf_events),
            '-I', '100',  # 100msé—´éš”
            '-x', ',',    # CSVæ ¼å¼è¾“å‡º
            '--pid', str(os.getpid())
        ]
        
        # ğŸ”¥ å¯åŠ¨perfè¿›ç¨‹
        self.perf_process = subprocess.Popen(
            perf_cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
    
    def stop_collection(self) -> List[Dict]:
        """åœæ­¢æ”¶é›†å¹¶è¿”å›æ•°æ®"""
        if self.perf_process:
            self.perf_process.terminate()
            stdout, stderr = self.perf_process.communicate()
            
            # ğŸ”¥ è§£æperfè¾“å‡º
            return self._parse_perf_output(stderr)
        
        return []
    
    def _parse_perf_output(self, perf_output: str) -> List[Dict]:
        """è§£æperfè¾“å‡º"""
        counter_data = []
        
        for line in perf_output.split('\n'):
            if line.strip() and not line.startswith('#'):
                parts = line.split(',')
                if len(parts) >= 3:
                    try:
                        counter_data.append({
                            'timestamp': float(parts[0]),
                            'value': int(parts[1]) if parts[1] != '<not counted>' else 0,
                            'event': parts[2].strip(),
                            'percentage': parts[3] if len(parts) > 3 else None
                        })
                    except (ValueError, IndexError):
                        continue
        
        return counter_data

class MemoryMonitor:
    """å†…å­˜ç›‘æ§å™¨"""
    
    def __init__(self):
        self.monitoring = False
        self.memory_data = []
        self.monitor_thread = None
    
    def start_monitoring(self):
        """å¼€å§‹å†…å­˜ç›‘æ§"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_memory)
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢å†…å­˜ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
    
    def _monitor_memory(self):
        """å†…å­˜ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            timestamp = time.time_ns()
            
            # ğŸ”¥ æ”¶é›†ç³»ç»Ÿå†…å­˜ä¿¡æ¯
            try:
                with open('/proc/meminfo', 'r') as f:
                    meminfo = {}
                    for line in f:
                        key, value = line.split(':')
                        meminfo[key.strip()] = int(value.split()[0]) * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
                
                # ğŸ”¥ æ”¶é›†è¿›ç¨‹å†…å­˜ä¿¡æ¯
                with open('/proc/self/status', 'r') as f:
                    process_mem = {}
                    for line in f:
                        if line.startswith(('VmSize:', 'VmRSS:', 'VmData:', 'VmStk:')):
                            key, value = line.split(':')
                            process_mem[key.strip()] = int(value.split()[0]) * 1024
                
                self.memory_data.append({
                    'timestamp_ns': timestamp,
                    'system_memory': meminfo,
                    'process_memory': process_mem
                })
                
            except (FileNotFoundError, ValueError):
                pass
            
            # ğŸ”¥ 1æ¯«ç§’é‡‡æ ·é—´éš”
            time.sleep(0.001)

class SystemCallTracer:
    """ç³»ç»Ÿè°ƒç”¨è¿½è¸ªå™¨"""
    
    def __init__(self):
        self.strace_process = None
        self.syscall_data = []
    
    def start_tracing(self, pid: int):
        """å¼€å§‹è¿½è¸ªç³»ç»Ÿè°ƒç”¨"""
        
        # ğŸ”¥ å¯åŠ¨straceè¿›ç¨‹
        strace_cmd = [
            'strace',
            '-p', str(pid),
            '-f',           # è·Ÿè¸ªå­è¿›ç¨‹
            '-T',           # æ˜¾ç¤ºç³»ç»Ÿè°ƒç”¨è€—æ—¶
            '-tt',          # æ˜¾ç¤ºå¾®ç§’æ—¶é—´æˆ³
            '-e', 'trace=mmap,munmap,mprotect,brk,sbrk,madvise',  # åªè¿½è¸ªå†…å­˜ç›¸å…³ç³»ç»Ÿè°ƒç”¨
            '-o', f'syscalls_{pid}.log'
        ]
        
        self.strace_process = subprocess.Popen(
            strace_cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
    
    def stop_tracing(self) -> List[Dict]:
        """åœæ­¢è¿½è¸ªå¹¶è§£ææ•°æ®"""
        if self.strace_process:
            self.strace_process.terminate()
            self.strace_process.wait()
            
            # ğŸ”¥ è§£æstraceè¾“å‡º
            return self._parse_strace_output()
        
        return []
    
    def _parse_strace_output(self) -> List[Dict]:
        """è§£æstraceè¾“å‡º"""
        syscall_data = []
        
        try:
            with open(f'syscalls_{self.strace_process.args[2]}.log', 'r') as f:
                for line in f:
                    if 'mmap' in line or 'munmap' in line or 'mprotect' in line:
                        # ğŸ”¥ è§£æç³»ç»Ÿè°ƒç”¨è¡Œ
                        parsed = self._parse_syscall_line(line.strip())
                        if parsed:
                            syscall_data.append(parsed)
        except FileNotFoundError:
            pass
        
        return syscall_data
    
    def _parse_syscall_line(self, line: str) -> Optional[Dict]:
        """è§£æå•è¡Œç³»ç»Ÿè°ƒç”¨"""
        import re
        
        # ğŸ”¥ åŒ¹é…ç³»ç»Ÿè°ƒç”¨æ¨¡å¼
        pattern = r'(\d+:\d+:\d+\.\d+)\s+(\w+)\((.*?)\)\s+=\s+(.*?)\s+<([\d.]+)>'
        match = re.match(pattern, line)
        
        if match:
            return {
                'timestamp': match.group(1),
                'syscall': match.group(2),
                'args': match.group(3),
                'result': match.group(4),
                'duration_us': float(match.group(5)) * 1_000_000  # è½¬æ¢ä¸ºçº³ç§’
            }
        
        return None

class JVMLogParser:
    """JVMæ—¥å¿—è§£æå™¨"""
    
    def parse_startup_log(self, log_file: str) -> List[Dict]:
        """è§£æJVMå¯åŠ¨æ—¥å¿—"""
        events = []
        
        try:
            with open(log_file, 'r') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    
                    # ğŸ”¥ è§£æä¸åŒç±»å‹çš„æ—¥å¿—è¡Œ
                    if 'vm_init_globals' in line:
                        events.append(self._parse_init_event(line, 'vm_init_globals'))
                    elif 'init_globals' in line:
                        events.append(self._parse_init_event(line, 'init_globals'))
                    elif 'universe_init' in line:
                        events.append(self._parse_init_event(line, 'universe_init'))
                    elif 'interpreter_init' in line:
                        events.append(self._parse_init_event(line, 'interpreter_init'))
                    elif 'compiler_init' in line:
                        events.append(self._parse_init_event(line, 'compiler_init'))
                    elif '[GC' in line:
                        events.append(self._parse_gc_event(line))
                    
        except FileNotFoundError:
            print(f"è­¦å‘Šï¼šæ— æ³•æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ {log_file}")
        
        return events
    
    def _parse_init_event(self, line: str, event_type: str) -> Dict:
        """è§£æåˆå§‹åŒ–äº‹ä»¶"""
        import re
        
        # ğŸ”¥ æå–æ—¶é—´æˆ³
        timestamp_match = re.search(r'(\d+\.\d+):', line)
        timestamp = float(timestamp_match.group(1)) if timestamp_match else 0.0
        
        return {
            'type': 'initialization',
            'event': event_type,
            'timestamp': timestamp,
            'raw_line': line
        }
    
    def _parse_gc_event(self, line: str) -> Dict:
        """è§£æGCäº‹ä»¶"""
        import re
        
        # ğŸ”¥ æå–GCä¿¡æ¯
        gc_match = re.search(r'\[GC.*?(\d+\.\d+)ms\]', line)
        duration = float(gc_match.group(1)) if gc_match else 0.0
        
        return {
            'type': 'gc',
            'event': 'garbage_collection',
            'duration_ms': duration,
            'raw_line': line
        }

class PerformanceReportGenerator:
    """æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, profiler_data: Dict):
        self.data = profiler_data
        self.events = profiler_data.get('events', [])
        self.perf_counters = profiler_data.get('perf_counters', [])
        self.memory_data = profiler_data.get('memory_data', [])
        self.syscall_data = profiler_data.get('syscall_data', [])
    
    def generate_comprehensive_report(self) -> Dict:
        """ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š"""
        
        report = {
            'summary': self._generate_summary(),
            'timing_analysis': self._analyze_timing(),
            'memory_analysis': self._analyze_memory(),
            'cpu_analysis': self._analyze_cpu_performance(),
            'syscall_analysis': self._analyze_syscalls(),
            'bottleneck_analysis': self._identify_bottlenecks(),
            'optimization_recommendations': self._generate_recommendations()
        }
        
        # ğŸ”¥ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self._generate_visualizations(report)
        
        return report
    
    def _generate_summary(self) -> Dict:
        """ç”Ÿæˆæ€§èƒ½æ‘˜è¦"""
        if not self.events:
            return {}
        
        start_time = min(event.timestamp_ns for event in self.events)
        end_time = max(event.timestamp_ns for event in self.events)
        total_duration_ms = (end_time - start_time) / 1_000_000
        
        return {
            'total_initialization_time_ms': total_duration_ms,
            'total_events_recorded': len(self.events),
            'start_timestamp_ns': start_time,
            'end_timestamp_ns': end_time,
            'average_event_interval_us': total_duration_ms * 1000 / len(self.events) if self.events else 0
        }
    
    def _analyze_timing(self) -> Dict:
        """åˆ†ææ—¶åºæ€§èƒ½"""
        phase_timings = defaultdict(list)
        
        # ğŸ”¥ æŒ‰é˜¶æ®µåˆ†ç»„äº‹ä»¶
        for event in self.events:
            phase_timings[event.event_type].append(event.timestamp_ns)
        
        # ğŸ”¥ è®¡ç®—æ¯ä¸ªé˜¶æ®µçš„ç»Ÿè®¡ä¿¡æ¯
        timing_stats = {}
        for phase, timestamps in phase_timings.items():
            if len(timestamps) >= 2:
                duration_ns = max(timestamps) - min(timestamps)
                timing_stats[phase] = {
                    'duration_ms': duration_ns / 1_000_000,
                    'start_time_ns': min(timestamps),
                    'end_time_ns': max(timestamps),
                    'event_count': len(timestamps)
                }
        
        return timing_stats
    
    def _analyze_memory(self) -> Dict:
        """åˆ†æå†…å­˜ä½¿ç”¨"""
        if not self.memory_data:
            return {}
        
        # ğŸ”¥ è®¡ç®—å†…å­˜ä½¿ç”¨ç»Ÿè®¡
        rss_values = [data['process_memory'].get('VmRSS', 0) for data in self.memory_data]
        vsize_values = [data['process_memory'].get('VmSize', 0) for data in self.memory_data]
        
        return {
            'peak_rss_mb': max(rss_values) / (1024 * 1024) if rss_values else 0,
            'peak_vsize_mb': max(vsize_values) / (1024 * 1024) if vsize_values else 0,
            'average_rss_mb': np.mean(rss_values) / (1024 * 1024) if rss_values else 0,
            'memory_growth_rate_mb_per_ms': self._calculate_memory_growth_rate(),
            'memory_samples': len(self.memory_data)
        }
    
    def _analyze_cpu_performance(self) -> Dict:
        """åˆ†æCPUæ€§èƒ½"""
        if not self.perf_counters:
            return {}
        
        # ğŸ”¥ èšåˆæ€§èƒ½è®¡æ•°å™¨æ•°æ®
        counter_totals = defaultdict(int)
        for counter in self.perf_counters:
            counter_totals[counter['event']] += counter['value']
        
        # ğŸ”¥ è®¡ç®—å…³é”®æ€§èƒ½æŒ‡æ ‡
        cycles = counter_totals.get('cycles', 0)
        instructions = counter_totals.get('instructions', 0)
        cache_refs = counter_totals.get('cache-references', 0)
        cache_misses = counter_totals.get('cache-misses', 0)
        
        return {
            'total_cpu_cycles': cycles,
            'total_instructions': instructions,
            'instructions_per_cycle': instructions / cycles if cycles > 0 else 0,
            'cache_hit_rate': (cache_refs - cache_misses) / cache_refs if cache_refs > 0 else 0,
            'cache_miss_rate': cache_misses / cache_refs if cache_refs > 0 else 0,
            'performance_counters': dict(counter_totals)
        }
    
    def _analyze_syscalls(self) -> Dict:
        """åˆ†æç³»ç»Ÿè°ƒç”¨"""
        if not self.syscall_data:
            return {}
        
        # ğŸ”¥ æŒ‰ç³»ç»Ÿè°ƒç”¨ç±»å‹åˆ†ç»„
        syscall_stats = defaultdict(lambda: {'count': 0, 'total_duration_ns': 0})
        
        for syscall in self.syscall_data:
            call_type = syscall['syscall']
            syscall_stats[call_type]['count'] += 1
            syscall_stats[call_type]['total_duration_ns'] += syscall['duration_us']
        
        # ğŸ”¥ è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        result = {}
        for call_type, stats in syscall_stats.items():
            result[call_type] = {
                'count': stats['count'],
                'total_duration_ms': stats['total_duration_ns'] / 1_000_000,
                'average_duration_us': stats['total_duration_ns'] / stats['count'] / 1000
            }
        
        return result
    
    def _identify_bottlenecks(self) -> List[Dict]:
        """è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ"""
        bottlenecks = []
        
        # ğŸ”¥ åˆ†ææ—¶åºç“¶é¢ˆ
        timing_analysis = self._analyze_timing()
        if timing_analysis:
            max_duration_phase = max(timing_analysis.items(), 
                                   key=lambda x: x[1]['duration_ms'])
            
            if max_duration_phase[1]['duration_ms'] > 50:  # è¶…è¿‡50ms
                bottlenecks.append({
                    'type': 'timing_bottleneck',
                    'phase': max_duration_phase[0],
                    'duration_ms': max_duration_phase[1]['duration_ms'],
                    'severity': 'high' if max_duration_phase[1]['duration_ms'] > 100 else 'medium'
                })
        
        # ğŸ”¥ åˆ†æå†…å­˜ç“¶é¢ˆ
        memory_analysis = self._analyze_memory()
        if memory_analysis.get('peak_rss_mb', 0) > 1000:  # è¶…è¿‡1GB
            bottlenecks.append({
                'type': 'memory_bottleneck',
                'peak_usage_mb': memory_analysis['peak_rss_mb'],
                'severity': 'high' if memory_analysis['peak_rss_mb'] > 2000 else 'medium'
            })
        
        # ğŸ”¥ åˆ†æCPUç“¶é¢ˆ
        cpu_analysis = self._analyze_cpu_performance()
        if cpu_analysis.get('cache_miss_rate', 0) > 0.1:  # ç¼“å­˜æœªå‘½ä¸­ç‡è¶…è¿‡10%
            bottlenecks.append({
                'type': 'cpu_cache_bottleneck',
                'cache_miss_rate': cpu_analysis['cache_miss_rate'],
                'severity': 'medium'
            })
        
        return bottlenecks
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # ğŸ”¥ åŸºäºç“¶é¢ˆåˆ†æç”Ÿæˆå»ºè®®
        bottlenecks = self._identify_bottlenecks()
        
        for bottleneck in bottlenecks:
            if bottleneck['type'] == 'timing_bottleneck':
                if bottleneck['phase'] == 'universe_init':
                    recommendations.append(
                        "è€ƒè™‘å¢åŠ åˆå§‹å †å¤§å°ä»¥å‡å°‘universe_inité˜¶æ®µçš„å†…å­˜åˆ†é…å¼€é”€"
                    )
                elif bottleneck['phase'] == 'compiler_init':
                    recommendations.append(
                        "è€ƒè™‘è°ƒæ•´ç¼–è¯‘å™¨çº¿ç¨‹æ•°æˆ–ç¦ç”¨åˆ†å±‚ç¼–è¯‘ä»¥åŠ é€Ÿcompiler_init"
                    )
            
            elif bottleneck['type'] == 'memory_bottleneck':
                recommendations.append(
                    "è€ƒè™‘ä½¿ç”¨å‹ç¼©æŒ‡é’ˆå’Œè°ƒæ•´å †å¤§å°ä»¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨"
                )
            
            elif bottleneck['type'] == 'cpu_cache_bottleneck':
                recommendations.append(
                    "è€ƒè™‘ä¼˜åŒ–æ•°æ®ç»“æ„å¸ƒå±€å’Œè®¿é—®æ¨¡å¼ä»¥æé«˜ç¼“å­˜å‘½ä¸­ç‡"
                )
        
        # ğŸ”¥ é€šç”¨ä¼˜åŒ–å»ºè®®
        if not bottlenecks:
            recommendations.append("JVMåˆå§‹åŒ–æ€§èƒ½è‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘è¿›ä¸€æ­¥çš„å¾®è°ƒä¼˜åŒ–")
        
        return recommendations
    
    def _generate_visualizations(self, report: Dict):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        
        # ğŸ”¥ è®¾ç½®å›¾è¡¨æ ·å¼
        plt.style.use('seaborn-v0_8')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('JVMåˆå§‹åŒ–æ€§èƒ½åˆ†ææŠ¥å‘Š', fontsize=16, fontweight='bold')
        
        # ğŸ”¥ å›¾è¡¨1ï¼šåˆå§‹åŒ–é˜¶æ®µæ—¶åº
        if report['timing_analysis']:
            phases = list(report['timing_analysis'].keys())
            durations = [report['timing_analysis'][phase]['duration_ms'] for phase in phases]
            
            axes[0, 0].bar(phases, durations, color='skyblue', alpha=0.7)
            axes[0, 0].set_title('åˆå§‹åŒ–é˜¶æ®µè€—æ—¶åˆ†æ')
            axes[0, 0].set_ylabel('è€—æ—¶ (ms)')
            axes[0, 0].tick_params(axis='x', rotation=45)
        
        # ğŸ”¥ å›¾è¡¨2ï¼šå†…å­˜ä½¿ç”¨è¶‹åŠ¿
        if self.memory_data:
            timestamps = [(data['timestamp_ns'] - self.memory_data[0]['timestamp_ns']) / 1_000_000 
                         for data in self.memory_data]
            rss_values = [data['process_memory'].get('VmRSS', 0) / (1024 * 1024) 
                         for data in self.memory_data]
            
            axes[0, 1].plot(timestamps, rss_values, color='green', linewidth=2)
            axes[0, 1].set_title('å†…å­˜ä½¿ç”¨è¶‹åŠ¿')
            axes[0, 1].set_xlabel('æ—¶é—´ (ms)')
            axes[0, 1].set_ylabel('RSSå†…å­˜ (MB)')
        
        # ğŸ”¥ å›¾è¡¨3ï¼šCPUæ€§èƒ½è®¡æ•°å™¨
        if report['cpu_analysis'].get('performance_counters'):
            counters = report['cpu_analysis']['performance_counters']
            # é€‰æ‹©ä¸»è¦çš„è®¡æ•°å™¨
            main_counters = {k: v for k, v in counters.items() 
                           if k in ['cycles', 'instructions', 'cache-misses', 'branch-misses']}
            
            if main_counters:
                names = list(main_counters.keys())
                values = list(main_counters.values())
                
                axes[1, 0].bar(names, values, color='orange', alpha=0.7)
                axes[1, 0].set_title('CPUæ€§èƒ½è®¡æ•°å™¨')
                axes[1, 0].set_ylabel('è®¡æ•°å€¼')
                axes[1, 0].tick_params(axis='x', rotation=45)
        
        # ğŸ”¥ å›¾è¡¨4ï¼šç³»ç»Ÿè°ƒç”¨åˆ†æ
        if report['syscall_analysis']:
            syscalls = list(report['syscall_analysis'].keys())
            counts = [report['syscall_analysis'][sc]['count'] for sc in syscalls]
            
            axes[1, 1].pie(counts, labels=syscalls, autopct='%1.1f%%', startangle=90)
            axes[1, 1].set_title('ç³»ç»Ÿè°ƒç”¨åˆ†å¸ƒ')
        
        plt.tight_layout()
        plt.savefig('jvm_init_performance_report.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("ğŸ“Š æ€§èƒ½åˆ†æå›¾è¡¨å·²ä¿å­˜ä¸º 'jvm_init_performance_report.png'")
    
    def _calculate_memory_growth_rate(self) -> float:
        """è®¡ç®—å†…å­˜å¢é•¿ç‡"""
        if len(self.memory_data) < 2:
            return 0.0
        
        first_sample = self.memory_data[0]
        last_sample = self.memory_data[-1]
        
        time_diff_ms = (last_sample['timestamp_ns'] - first_sample['timestamp_ns']) / 1_000_000
        memory_diff_mb = (last_sample['process_memory'].get('VmRSS', 0) - 
                         first_sample['process_memory'].get('VmRSS', 0)) / (1024 * 1024)
        
        return memory_diff_mb / time_diff_ms if time_diff_ms > 0 else 0.0

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='JVMåˆå§‹åŒ–æç»†è‡´æ€§èƒ½å‰–æå·¥å…·')
    parser.add_argument('main_class', help='Javaä¸»ç±»å')
    parser.add_argument('-Xms', '--initial-heap', default='8g', help='åˆå§‹å †å¤§å°')
    parser.add_argument('-Xmx', '--max-heap', default='8g', help='æœ€å¤§å †å¤§å°')
    parser.add_argument('--gc', default='G1GC', help='åƒåœ¾æ”¶é›†å™¨')
    parser.add_argument('--output', default='jvm_performance_report.json', help='è¾“å‡ºæ–‡ä»¶')
    
    args = parser.parse_args()
    
    # ğŸ”¥ æ„å»ºJVMå‚æ•°
    jvm_args = [
        f'-Xms{args.initial_heap}',
        f'-Xmx{args.max_heap}',
        f'-XX:+Use{args.gc}',
        '-XX:-UseLargePages',
        '-server'
    ]
    
    # ğŸ”¥ åˆ›å»ºæ€§èƒ½å‰–æå™¨
    profiler = JVMInitProfiler(jvm_args, args.main_class)
    
    try:
        # ğŸ”¥ æ‰§è¡Œæ€§èƒ½å‰–æ
        profile_data = profiler.profile_jvm_initialization()
        
        # ğŸ”¥ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        report_generator = PerformanceReportGenerator(profile_data)
        report = report_generator.generate_comprehensive_report()
        
        # ğŸ”¥ ä¿å­˜æŠ¥å‘Š
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ğŸ”¥ æ‰“å°æ‘˜è¦
        print("\n" + "="*80)
        print("ğŸš€ JVMåˆå§‹åŒ–æ€§èƒ½å‰–æå®Œæˆ")
        print("="*80)
        
        if 'summary' in report:
            summary = report['summary']
            print(f"ğŸ“Š æ€»åˆå§‹åŒ–æ—¶é—´: {summary.get('total_initialization_time_ms', 0):.2f} ms")
            print(f"ğŸ“Š è®°å½•äº‹ä»¶æ•°é‡: {summary.get('total_events_recorded', 0)}")
            print(f"ğŸ“Š å¹³å‡äº‹ä»¶é—´éš”: {summary.get('average_event_interval_us', 0):.2f} Î¼s")
        
        if 'bottleneck_analysis' in report and report['bottleneck_analysis']:
            print(f"\nâš ï¸  å‘ç° {len(report['bottleneck_analysis'])} ä¸ªæ€§èƒ½ç“¶é¢ˆ")
            for bottleneck in report['bottleneck_analysis']:
                print(f"   - {bottleneck['type']}: {bottleneck.get('severity', 'unknown')} ä¸¥é‡ç¨‹åº¦")
        
        if 'optimization_recommendations' in report:
            print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for i, recommendation in enumerate(report['optimization_recommendations'], 1):
                print(f"   {i}. {recommendation}")
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
        print("ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: jvm_init_performance_report.png")
        
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­äº†æ€§èƒ½å‰–æ")
    except Exception as e:
        print(f"\nâŒ æ€§èƒ½å‰–æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ğŸ”¥ æ¸…ç†èµ„æº
        if hasattr(profiler, 'perf_counters'):
            profiler.perf_counters.stop_collection()
        if hasattr(profiler, 'memory_monitor'):
            profiler.memory_monitor.stop_monitoring()
        if hasattr(profiler, 'syscall_tracer'):
            profiler.syscall_tracer.stop_tracing()

if __name__ == '__main__':
    main()
```

### ğŸ” é…å¥—çš„GDBå¢å¼ºè°ƒè¯•è„šæœ¬

```bash
#!/bin/bash
# ğŸ”¥ JVMåˆå§‹åŒ–æç»†è‡´GDBè°ƒè¯•è„šæœ¬
# æ–‡ä»¶ï¼šultra_precise_gdb_debugger.sh

set -euo pipefail

# ğŸ”¥ é…ç½®å‚æ•°
JVM_BINARY="java"
MAIN_CLASS="HelloWorld"
JVM_ARGS="-Xms8g -Xmx8g -XX:+UseG1GC -XX:-UseLargePages"
GDB_SCRIPT="ultra_precise_debug.gdb"

# ğŸ”¥ åˆ›å»ºé«˜ç²¾åº¦GDBè°ƒè¯•è„šæœ¬
cat > "$GDB_SCRIPT" << 'EOF'
# ğŸ”¥ JVMåˆå§‹åŒ–æç»†è‡´GDBè°ƒè¯•è„šæœ¬

# è®¾ç½®è°ƒè¯•ç¯å¢ƒ
set confirm off
set pagination off
set print pretty on
set print array on
set print array-indexes on

# ğŸ”¥ å®šä¹‰é¢œè‰²è¾“å‡ºå®
define color_print
    if $argc == 2
        printf "\033[%s%s\033[0m\n", $arg0, $arg1
    else
        printf "\033[31mé”™è¯¯ï¼šcolor_printéœ€è¦2ä¸ªå‚æ•°\033[0m\n"
    end
end

# ğŸ”¥ å®šä¹‰æ—¶é—´æˆ³è·å–å‡½æ•°
define get_timestamp
    python
import time
timestamp_ns = time.time_ns()
gdb.write(f"å½“å‰æ—¶é—´æˆ³: {timestamp_ns} ns\n")
gdb.set_convenience_variable("timestamp_ns", timestamp_ns)
    end
end

# ğŸ”¥ å®šä¹‰å†…å­˜ä½¿ç”¨ç›‘æ§å‡½æ•°
define monitor_memory
    python
import os
try:
    with open('/proc/self/status', 'r') as f:
        for line in f:
            if line.startswith('VmRSS:'):
                rss_kb = int(line.split()[1])
                gdb.write(f"å½“å‰å†…å­˜ä½¿ç”¨: {rss_kb} KB ({rss_kb/1024:.1f} MB)\n")
                gdb.set_convenience_variable("memory_rss_kb", rss_kb)
                break
except:
    gdb.write("æ— æ³•è·å–å†…å­˜ä½¿ç”¨ä¿¡æ¯\n")
    end
end

# ğŸ”¥ å®šä¹‰CPUç¼“å­˜ç›‘æ§å‡½æ•°
define monitor_cpu_cache
    python
import subprocess
try:
    result = subprocess.run(['perf', 'stat', '-e', 'cache-misses,cache-references', 
                           '--pid', str(gdb.selected_inferior().pid), 
                           'sleep', '0.1'], 
                          capture_output=True, text=True, timeout=5)
    if result.stderr:
        lines = result.stderr.split('\n')
        for line in lines:
            if 'cache-misses' in line or 'cache-references' in line:
                gdb.write(f"ç¼“å­˜ç»Ÿè®¡: {line.strip()}\n")
except:
    gdb.write("æ— æ³•è·å–CPUç¼“å­˜ç»Ÿè®¡\n")
    end
end

# ğŸ”¥ JVMåˆå§‹åŒ–å…³é”®æ–­ç‚¹è®¾ç½®
define setup_jvm_breakpoints
    color_print "32m" "ğŸ”¥ è®¾ç½®JVMåˆå§‹åŒ–å…³é”®æ–­ç‚¹..."
    
    # ğŸ”¥ vm_init_globalsæ–­ç‚¹
    break vm_init_globals
    commands
        silent
        get_timestamp
        monitor_memory
        color_print "33m" "ğŸ“ è¿›å…¥vm_init_globals()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  å†…å­˜ä½¿ç”¨: %d KB\n", $memory_rss_kb
        continue
    end
    
    # ğŸ”¥ basic_types_initæ–­ç‚¹
    break basic_types_init
    commands
        silent
        get_timestamp
        color_print "33m" "ğŸ“ è¿›å…¥basic_types_init()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        # æ£€æŸ¥ç±»å‹å¤§å°æ–­è¨€
        printf "  sizeof(intx): %d\n", sizeof(intx)
        printf "  sizeof(jobject): %d\n", sizeof(jobject)
        continue
    end
    
    # ğŸ”¥ mutex_initæ–­ç‚¹
    break mutex_init
    commands
        silent
        get_timestamp
        monitor_memory
        color_print "33m" "ğŸ“ è¿›å…¥mutex_init()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  å†…å­˜ä½¿ç”¨: %d KB\n", $memory_rss_kb
        continue
    end
    
    # ğŸ”¥ universe_initæ–­ç‚¹
    break universe_init
    commands
        silent
        get_timestamp
        monitor_memory
        monitor_cpu_cache
        color_print "31m" "ğŸ“ è¿›å…¥universe_init() - å…³é”®é˜¶æ®µ"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  å†…å­˜ä½¿ç”¨: %d KB\n", $memory_rss_kb
        continue
    end
    
    # ğŸ”¥ Universe::initialize_heapæ–­ç‚¹
    break Universe::initialize_heap
    commands
        silent
        get_timestamp
        monitor_memory
        color_print "31m" "ğŸ“ è¿›å…¥Universe::initialize_heap() - å †åˆå§‹åŒ–"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  å†…å­˜ä½¿ç”¨: %d KB\n", $memory_rss_kb
        # æ˜¾ç¤ºå †é…ç½®å‚æ•°
        printf "  InitialHeapSize: %ld bytes\n", InitialHeapSize
        printf "  MaxHeapSize: %ld bytes\n", MaxHeapSize
        continue
    end
    
    # ğŸ”¥ G1CollectedHeap::initializeæ–­ç‚¹
    break G1CollectedHeap::initialize
    commands
        silent
        get_timestamp
        monitor_memory
        color_print "35m" "ğŸ“ è¿›å…¥G1CollectedHeap::initialize()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  å†…å­˜ä½¿ç”¨: %d KB\n", $memory_rss_kb
        continue
    end
    
    # ğŸ”¥ interpreter_initæ–­ç‚¹
    break interpreter_init
    commands
        silent
        get_timestamp
        color_print "33m" "ğŸ“ è¿›å…¥interpreter_init()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        continue
    end
    
    # ğŸ”¥ templateTable_initæ–­ç‚¹
    break templateTable_init
    commands
        silent
        get_timestamp
        color_print "33m" "ğŸ“ è¿›å…¥templateTable_init()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        continue
    end
    
    # ğŸ”¥ CompileBroker::compilation_initæ–­ç‚¹
    break CompileBroker::compilation_init
    commands
        silent
        get_timestamp
        monitor_memory
        color_print "36m" "ğŸ“ è¿›å…¥CompileBroker::compilation_init()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  å†…å­˜ä½¿ç”¨: %d KB\n", $memory_rss_kb
        continue
    end
    
    color_print "32m" "âœ… JVMåˆå§‹åŒ–æ–­ç‚¹è®¾ç½®å®Œæˆ"
end

# ğŸ”¥ å†…å­˜åˆ†é…ç›‘æ§æ–­ç‚¹
define setup_memory_breakpoints
    color_print "32m" "ğŸ”¥ è®¾ç½®å†…å­˜åˆ†é…ç›‘æ§æ–­ç‚¹..."
    
    # ğŸ”¥ mmapç³»ç»Ÿè°ƒç”¨æ–­ç‚¹
    break mmap
    commands
        silent
        get_timestamp
        color_print "34m" "ğŸ“ mmapç³»ç»Ÿè°ƒç”¨"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  åœ°å€: 0x%lx\n", $rdi
        printf "  å¤§å°: %ld bytes (%.1f MB)\n", $rsi, $rsi/1024.0/1024.0
        printf "  ä¿æŠ¤: 0x%x\n", $rdx
        printf "  æ ‡å¿—: 0x%x\n", $rcx
        continue
    end
    
    # ğŸ”¥ os::reserve_memoryæ–­ç‚¹
    break os::reserve_memory
    commands
        silent
        get_timestamp
        monitor_memory
        color_print "34m" "ğŸ“ os::reserve_memory()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  è¯·æ±‚å¤§å°: %ld bytes (%.1f MB)\n", $rdi, $rdi/1024.0/1024.0
        printf "  å½“å‰å†…å­˜: %d KB\n", $memory_rss_kb
        continue
    end
    
    # ğŸ”¥ os::commit_memoryæ–­ç‚¹
    break os::commit_memory
    commands
        silent
        get_timestamp
        monitor_memory
        color_print "34m" "ğŸ“ os::commit_memory()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  æäº¤å¤§å°: %ld bytes (%.1f MB)\n", $rsi, $rsi/1024.0/1024.0
        printf "  å½“å‰å†…å­˜: %d KB\n", $memory_rss_kb
        continue
    end
    
    color_print "32m" "âœ… å†…å­˜åˆ†é…ç›‘æ§æ–­ç‚¹è®¾ç½®å®Œæˆ"
end

# ğŸ”¥ å‹ç¼©æŒ‡é’ˆç›‘æ§æ–­ç‚¹
define setup_compressed_oop_breakpoints
    color_print "32m" "ğŸ”¥ è®¾ç½®å‹ç¼©æŒ‡é’ˆç›‘æ§æ–­ç‚¹..."
    
    # ğŸ”¥ Universe::choose_heap_base_addressæ–­ç‚¹
    break Universe::choose_heap_base_address
    commands
        silent
        get_timestamp
        color_print "35m" "ğŸ“ Universe::choose_heap_base_address()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        continue
    end
    
    # ğŸ”¥ å‹ç¼©æŒ‡é’ˆé…ç½®å®Œæˆæ–­ç‚¹
    break Universe::set_narrow_oop_base
    commands
        silent
        get_timestamp
        color_print "35m" "ğŸ“ å‹ç¼©æŒ‡é’ˆé…ç½®: Universe::set_narrow_oop_base()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  åŸºå€: 0x%lx\n", $rdi
        continue
    end
    
    color_print "32m" "âœ… å‹ç¼©æŒ‡é’ˆç›‘æ§æ–­ç‚¹è®¾ç½®å®Œæˆ"
end

# ğŸ”¥ æ€§èƒ½å…³é”®è·¯å¾„ç›‘æ§
define setup_performance_breakpoints
    color_print "32m" "ğŸ”¥ è®¾ç½®æ€§èƒ½å…³é”®è·¯å¾„ç›‘æ§æ–­ç‚¹..."
    
    # ğŸ”¥ CodeCache::initializeæ–­ç‚¹
    break CodeCache::initialize
    commands
        silent
        get_timestamp
        monitor_memory
        color_print "36m" "ğŸ“ CodeCache::initialize()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        printf "  å†…å­˜ä½¿ç”¨: %d KB\n", $memory_rss_kb
        continue
    end
    
    # ğŸ”¥ SymbolTable::create_tableæ–­ç‚¹
    break SymbolTable::create_table
    commands
        silent
        get_timestamp
        color_print "33m" "ğŸ“ SymbolTable::create_table()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        continue
    end
    
    # ğŸ”¥ StringTable::create_tableæ–­ç‚¹
    break StringTable::create_table
    commands
        silent
        get_timestamp
        color_print "33m" "ğŸ“ StringTable::create_table()"
        printf "  æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
        continue
    end
    
    color_print "32m" "âœ… æ€§èƒ½å…³é”®è·¯å¾„ç›‘æ§æ–­ç‚¹è®¾ç½®å®Œæˆ"
end

# ğŸ”¥ ä¸»è°ƒè¯•å‡½æ•°
define ultra_precise_debug
    color_print "31m" "ğŸš€ å¼€å§‹JVMåˆå§‹åŒ–æç»†è‡´è°ƒè¯•"
    color_print "32m" "é…ç½®: 8GBå † + G1GC + éå¤§é¡µ"
    
    # è®¾ç½®æ‰€æœ‰æ–­ç‚¹
    setup_jvm_breakpoints
    setup_memory_breakpoints
    setup_compressed_oop_breakpoints
    setup_performance_breakpoints
    
    # ğŸ”¥ å¼€å§‹æ‰§è¡Œ
    color_print "32m" "â–¶ï¸  å¼€å§‹æ‰§è¡ŒJVM..."
    get_timestamp
    set $start_timestamp = $timestamp_ns
    
    run
    
    # ğŸ”¥ è®¡ç®—æ€»æ‰§è¡Œæ—¶é—´
    get_timestamp
    set $end_timestamp = $timestamp_ns
    set $total_time_ms = ($end_timestamp - $start_timestamp) / 1000000
    
    color_print "31m" "ğŸ JVMåˆå§‹åŒ–å®Œæˆ"
    printf "æ€»æ‰§è¡Œæ—¶é—´: %ld ms\n", $total_time_ms
    
    # ğŸ”¥ æ˜¾ç¤ºæœ€ç»ˆå†…å­˜ä½¿ç”¨
    monitor_memory
    printf "æœ€ç»ˆå†…å­˜ä½¿ç”¨: %d KB (%.1f MB)\n", $memory_rss_kb, $memory_rss_kb/1024.0
end

# ğŸ”¥ å¿«é€ŸçŠ¶æ€æ£€æŸ¥å‡½æ•°
define quick_status
    color_print "33m" "ğŸ“Š å¿«é€ŸçŠ¶æ€æ£€æŸ¥"
    get_timestamp
    monitor_memory
    monitor_cpu_cache
    
    printf "å½“å‰æ—¶é—´æˆ³: %ld ns\n", $timestamp_ns
    printf "å†…å­˜ä½¿ç”¨: %d KB (%.1f MB)\n", $memory_rss_kb, $memory_rss_kb/1024.0
    
    # ğŸ”¥ æ˜¾ç¤ºå½“å‰å‡½æ•°è°ƒç”¨æ ˆ
    color_print "33m" "ğŸ“‹ å½“å‰è°ƒç”¨æ ˆ:"
    bt 5
end

# ğŸ”¥ å†…å­˜å¸ƒå±€åˆ†æå‡½æ•°
define analyze_memory_layout
    color_print "33m" "ğŸ—ºï¸  å†…å­˜å¸ƒå±€åˆ†æ"
    
    python
import gdb
try:
    # è·å–å †ä¿¡æ¯
    heap_base = gdb.parse_and_eval("Universe::_heap->_reserved.base()")
    heap_size = gdb.parse_and_eval("Universe::_heap->_reserved.size()")
    
    print(f"Javaå †åŸºå€: 0x{int(heap_base):x}")
    print(f"Javaå †å¤§å°: {int(heap_size)} bytes ({int(heap_size)/1024/1024/1024:.1f} GB)")
    
    # è·å–å‹ç¼©æŒ‡é’ˆä¿¡æ¯
    if gdb.parse_and_eval("UseCompressedOops"):
        narrow_oop_base = gdb.parse_and_eval("Universe::_narrow_oop._base")
        narrow_oop_shift = gdb.parse_and_eval("Universe::_narrow_oop._shift")
        print(f"å‹ç¼©æŒ‡é’ˆåŸºå€: 0x{int(narrow_oop_base):x}")
        print(f"å‹ç¼©æŒ‡é’ˆä½ç§»: {int(narrow_oop_shift)}")
    
except:
    print("æ— æ³•è·å–å†…å­˜å¸ƒå±€ä¿¡æ¯ï¼ˆå¯èƒ½JVMå°šæœªå®Œå…¨åˆå§‹åŒ–ï¼‰")
    end
end

# ğŸ”¥ æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
define ultra_debug_help
    color_print "32m" "ğŸ”§ JVMåˆå§‹åŒ–æç»†è‡´è°ƒè¯•å·¥å…·å¸®åŠ©"
    printf "å¯ç”¨å‘½ä»¤:\n"
    printf "  ultra_precise_debug  - å¼€å§‹å®Œæ•´çš„æç»†è‡´è°ƒè¯•\n"
    printf "  quick_status         - å¿«é€ŸçŠ¶æ€æ£€æŸ¥\n"
    printf "  analyze_memory_layout - åˆ†æå†…å­˜å¸ƒå±€\n"
    printf "  monitor_memory       - ç›‘æ§å†…å­˜ä½¿ç”¨\n"
    printf "  monitor_cpu_cache    - ç›‘æ§CPUç¼“å­˜\n"
    printf "  get_timestamp        - è·å–å½“å‰æ—¶é—´æˆ³\n"
    printf "  ultra_debug_help     - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯\n"
end

# ğŸ”¥ åˆå§‹åŒ–æ¶ˆæ¯
color_print "31m" "ğŸš€ JVMåˆå§‹åŒ–æç»†è‡´GDBè°ƒè¯•å™¨å·²åŠ è½½"
color_print "32m" "è¾“å…¥ 'ultra_debug_help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤"
color_print "32m" "è¾“å…¥ 'ultra_precise_debug' å¼€å§‹è°ƒè¯•"

EOF

# ğŸ”¥ å¯åŠ¨GDBè°ƒè¯•
echo "ğŸš€ å¯åŠ¨JVMåˆå§‹åŒ–æç»†è‡´GDBè°ƒè¯•..."
echo "é…ç½®: $JVM_ARGS"
echo "ä¸»ç±»: $MAIN_CLASS"

gdb -x "$GDB_SCRIPT" --args $JVM_BINARY $JVM_ARGS $MAIN_CLASS

# ğŸ”¥ æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -f "$GDB_SCRIPT"

echo "âœ… è°ƒè¯•ä¼šè¯ç»“æŸ"
```

### ğŸ” ç³»ç»Ÿè°ƒç”¨çº§åˆ«çš„è¿½è¸ªè„šæœ¬

```bash
#!/bin/bash
# ğŸ”¥ JVMåˆå§‹åŒ–ç³»ç»Ÿè°ƒç”¨æç»†è‡´è¿½è¸ªè„šæœ¬
# æ–‡ä»¶ï¼šsyscall_tracer.sh

set -euo pipefail

# ğŸ”¥ é…ç½®å‚æ•°
JVM_ARGS="-Xms8g -Xmx8g -XX:+UseG1GC -XX:-UseLargePages"
MAIN_CLASS="HelloWorld"
OUTPUT_DIR="jvm_syscall_analysis"
TRACE_DURATION=30  # è¿½è¸ª30ç§’

# ğŸ”¥ åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "$OUTPUT_DIR"
cd "$OUTPUT_DIR"

echo "ğŸš€ JVMåˆå§‹åŒ–ç³»ç»Ÿè°ƒç”¨æç»†è‡´è¿½è¸ª"
echo "é…ç½®: $JVM_ARGS"
echo "è¾“å‡ºç›®å½•: $(pwd)"

# ğŸ”¥ å¯åŠ¨JVMè¿›ç¨‹ï¼ˆåå°è¿è¡Œï¼‰
echo "â–¶ï¸  å¯åŠ¨JVMè¿›ç¨‹..."
java $JVM_ARGS $MAIN_CLASS &
JVM_PID=$!

echo "JVMè¿›ç¨‹PID: $JVM_PID"

# ğŸ”¥ ç­‰å¾…JVMè¿›ç¨‹å¯åŠ¨
sleep 2

# ğŸ”¥ å¯åŠ¨å¤šç§ç³»ç»Ÿè°ƒç”¨è¿½è¸ª
echo "ğŸ” å¯åŠ¨ç³»ç»Ÿè°ƒç”¨è¿½è¸ª..."

# ğŸ”¥ 1. å®Œæ•´ç³»ç»Ÿè°ƒç”¨è¿½è¸ª
strace -f -T -tt -o full_syscalls.log -p $JVM_PID &
STRACE_PID=$!

# ğŸ”¥ 2. å†…å­˜ç›¸å…³ç³»ç»Ÿè°ƒç”¨è¿½è¸ª
strace -f -T -tt -e trace=mmap,munmap,mprotect,brk,sbrk,madvise,mlock,munlock \
       -o memory_syscalls.log -p $JVM_PID &
MEMORY_STRACE_PID=$!

# ğŸ”¥ 3. æ–‡ä»¶ç›¸å…³ç³»ç»Ÿè°ƒç”¨è¿½è¸ª
strace -f -T -tt -e trace=open,openat,close,read,write,lseek,stat,fstat \
       -o file_syscalls.log -p $JVM_PID &
FILE_STRACE_PID=$!

# ğŸ”¥ 4. è¿›ç¨‹/çº¿ç¨‹ç›¸å…³ç³»ç»Ÿè°ƒç”¨è¿½è¸ª
strace -f -T -tt -e trace=clone,fork,vfork,execve,exit,exit_group,wait4 \
       -o process_syscalls.log -p $JVM_PID &
PROCESS_STRACE_PID=$!

# ğŸ”¥ å¯åŠ¨æ€§èƒ½ç›‘æ§
echo "ğŸ“Š å¯åŠ¨æ€§èƒ½ç›‘æ§..."

# ğŸ”¥ perfç›‘æ§
perf record -g -p $JVM_PID -o jvm_perf.data &
PERF_PID=$!

# ğŸ”¥ iotopç›‘æ§
iotop -a -o -d 1 -p $JVM_PID > iotop.log &
IOTOP_PID=$!

# ğŸ”¥ ç›‘æ§è¿›ç¨‹çŠ¶æ€
echo "ğŸ“ˆ ç›‘æ§è¿›ç¨‹çŠ¶æ€..."
(
    echo "timestamp,pid,state,utime,stime,vsize,rss,threads" > process_stats.csv
    while kill -0 $JVM_PID 2>/dev/null; do
        timestamp=$(date +%s.%N)
        if [ -f "/proc/$JVM_PID/stat" ]; then
            read -r pid comm state ppid pgrp session tty_nr tpgid flags minflt \
                    cminflt majflt cmajflt utime stime cutime cstime priority nice \
                    num_threads itrealvalue starttime vsize rss rsslim \
                    < /proc/$JVM_PID/stat
            
            echo "$timestamp,$pid,$state,$utime,$stime,$vsize,$rss,$num_threads" >> process_stats.csv
        fi
        sleep 0.1
    done
) &
MONITOR_PID=$!

# ğŸ”¥ ç›‘æ§å†…å­˜æ˜ å°„
echo "ğŸ—ºï¸  ç›‘æ§å†…å­˜æ˜ å°„..."
(
    mkdir -p memory_maps
    counter=0
    while kill -0 $JVM_PID 2>/dev/null; do
        timestamp=$(date +%s.%N)
        if [ -f "/proc/$JVM_PID/maps" ]; then
            cp "/proc/$JVM_PID/maps" "memory_maps/maps_${counter}_${timestamp}.txt"
        fi
        if [ -f "/proc/$JVM_PID/smaps" ]; then
            cp "/proc/$JVM_PID/smaps" "memory_maps/smaps_${counter}_${timestamp}.txt"
        fi
        counter=$((counter + 1))
        sleep 1
    done
) &
MEMORY_MAP_PID=$!

# ğŸ”¥ ç­‰å¾…JVMè¿›ç¨‹å®Œæˆæˆ–è¶…æ—¶
echo "â³ ç­‰å¾…JVMè¿›ç¨‹å®Œæˆï¼ˆæœ€å¤š${TRACE_DURATION}ç§’ï¼‰..."
timeout $TRACE_DURATION wait $JVM_PID || true

# ğŸ”¥ åœæ­¢æ‰€æœ‰ç›‘æ§è¿›ç¨‹
echo "ğŸ›‘ åœæ­¢ç›‘æ§è¿›ç¨‹..."
for pid in $STRACE_PID $MEMORY_STRACE_PID $FILE_STRACE_PID $PROCESS_STRACE_PID \
           $PERF_PID $IOTOP_PID $MONITOR_PID $MEMORY_MAP_PID; do
    kill $pid 2>/dev/null || true
done

# ğŸ”¥ ç­‰å¾…æ‰€æœ‰åå°è¿›ç¨‹ç»“æŸ
sleep 2

# ğŸ”¥ åˆ†æç³»ç»Ÿè°ƒç”¨æ•°æ®
echo "ğŸ“Š åˆ†æç³»ç»Ÿè°ƒç”¨æ•°æ®..."

# ğŸ”¥ åˆ›å»ºç³»ç»Ÿè°ƒç”¨åˆ†æè„šæœ¬
cat > analyze_syscalls.py << 'EOF'
#!/usr/bin/env python3
import re
import json
from collections import defaultdict, Counter
from datetime import datetime

def parse_strace_log(filename):
    """è§£æstraceæ—¥å¿—æ–‡ä»¶"""
    syscalls = []
    
    try:
        with open(filename, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('strace:'):
                    continue
                
                # è§£ææ—¶é—´æˆ³å’Œç³»ç»Ÿè°ƒç”¨
                match = re.match(r'(\d+:\d+:\d+\.\d+)\s+(\w+)\((.*?)\)\s+=\s+(.*?)\s+<([\d.]+)>', line)
                if match:
                    timestamp, syscall, args, result, duration = match.groups()
                    
                    syscalls.append({
                        'timestamp': timestamp,
                        'syscall': syscall,
                        'args': args,
                        'result': result,
                        'duration_us': float(duration) * 1000000,  # è½¬æ¢ä¸ºå¾®ç§’
                        'raw_line': line
                    })
    except FileNotFoundError:
        print(f"è­¦å‘Š: æ— æ³•æ‰¾åˆ°æ–‡ä»¶ {filename}")
    
    return syscalls

def analyze_memory_syscalls(syscalls):
    """åˆ†æå†…å­˜ç›¸å…³ç³»ç»Ÿè°ƒç”¨"""
    memory_ops = defaultdict(list)
    total_allocated = 0
    total_freed = 0
    
    for call in syscalls:
        if call['syscall'] == 'mmap':
            # è§£æmmapå‚æ•°
            args = call['args']
            size_match = re.search(r'(\d+)', args)
            if size_match:
                size = int(size_match.group(1))
                memory_ops['mmap'].append({
                    'timestamp': call['timestamp'],
                    'size': size,
                    'duration_us': call['duration_us']
                })
                total_allocated += size
        
        elif call['syscall'] == 'munmap':
            # è§£æmunmapå‚æ•°
            args = call['args']
            size_match = re.search(r'(\d+)', args)
            if size_match:
                size = int(size_match.group(1))
                memory_ops['munmap'].append({
                    'timestamp': call['timestamp'],
                    'size': size,
                    'duration_us': call['duration_us']
                })
                total_freed += size
    
    return {
        'memory_operations': dict(memory_ops),
        'total_allocated_bytes': total_allocated,
        'total_freed_bytes': total_freed,
        'net_allocated_bytes': total_allocated - total_freed
    }

def analyze_syscall_performance(syscalls):
    """åˆ†æç³»ç»Ÿè°ƒç”¨æ€§èƒ½"""
    syscall_stats = defaultdict(lambda: {
        'count': 0,
        'total_duration_us': 0,
        'min_duration_us': float('inf'),
        'max_duration_us': 0
    })
    
    for call in syscalls:
        syscall_name = call['syscall']
        duration = call['duration_us']
        
        stats = syscall_stats[syscall_name]
        stats['count'] += 1
        stats['total_duration_us'] += duration
        stats['min_duration_us'] = min(stats['min_duration_us'], duration)
        stats['max_duration_us'] = max(stats['max_duration_us'], duration)
    
    # è®¡ç®—å¹³å‡å€¼
    for stats in syscall_stats.values():
        if stats['count'] > 0:
            stats['avg_duration_us'] = stats['total_duration_us'] / stats['count']
    
    return dict(syscall_stats)

def generate_syscall_report():
    """ç”Ÿæˆç³»ç»Ÿè°ƒç”¨åˆ†ææŠ¥å‘Š"""
    
    # è§£æå„ç§ç³»ç»Ÿè°ƒç”¨æ—¥å¿—
    full_syscalls = parse_strace_log('full_syscalls.log')
    memory_syscalls = parse_strace_log('memory_syscalls.log')
    file_syscalls = parse_strace_log('file_syscalls.log')
    process_syscalls = parse_strace_log('process_syscalls.log')
    
    # åˆ†æå†…å­˜æ“ä½œ
    memory_analysis = analyze_memory_syscalls(memory_syscalls)
    
    # åˆ†ææ€§èƒ½
    performance_analysis = analyze_syscall_performance(full_syscalls)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = {
        'summary': {
            'total_syscalls': len(full_syscalls),
            'memory_syscalls': len(memory_syscalls),
            'file_syscalls': len(file_syscalls),
            'process_syscalls': len(process_syscalls)
        },
        'memory_analysis': memory_analysis,
        'performance_analysis': performance_analysis,
        'top_syscalls_by_count': dict(Counter(call['syscall'] for call in full_syscalls).most_common(10)),
        'top_syscalls_by_duration': sorted(
            [(name, stats['total_duration_us']) for name, stats in performance_analysis.items()],
            key=lambda x: x[1], reverse=True
        )[:10]
    }
    
    # ä¿å­˜æŠ¥å‘Š
    with open('syscall_analysis_report.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    # æ‰“å°æ‘˜è¦
    print("ğŸ” ç³»ç»Ÿè°ƒç”¨åˆ†ææŠ¥å‘Š")
    print("=" * 50)
    print(f"æ€»ç³»ç»Ÿè°ƒç”¨æ•°: {report['summary']['total_syscalls']}")
    print(f"å†…å­˜ç›¸å…³è°ƒç”¨: {report['summary']['memory_syscalls']}")
    print(f"æ–‡ä»¶ç›¸å…³è°ƒç”¨: {report['summary']['file_syscalls']}")
    print(f"è¿›ç¨‹ç›¸å…³è°ƒç”¨: {report['summary']['process_syscalls']}")
    
    print(f"\nå†…å­˜åˆ†é…æ€»é‡: {memory_analysis['total_allocated_bytes'] / 1024 / 1024:.1f} MB")
    print(f"å†…å­˜é‡Šæ”¾æ€»é‡: {memory_analysis['total_freed_bytes'] / 1024 / 1024:.1f} MB")
    print(f"å‡€å†…å­˜åˆ†é…: {memory_analysis['net_allocated_bytes'] / 1024 / 1024:.1f} MB")
    
    print("\nğŸ”¥ è°ƒç”¨æ¬¡æ•°æœ€å¤šçš„ç³»ç»Ÿè°ƒç”¨:")
    for i, (syscall, count) in enumerate(report['top_syscalls_by_count'].items(), 1):
        print(f"  {i}. {syscall}: {count} æ¬¡")
    
    print("\nâ±ï¸  è€—æ—¶æœ€é•¿çš„ç³»ç»Ÿè°ƒç”¨:")
    for i, (syscall, duration) in enumerate(report['top_syscalls_by_duration'], 1):
        print(f"  {i}. {syscall}: {duration:.0f} Î¼s")

if __name__ == '__main__':
    generate_syscall_report()
EOF

# ğŸ”¥ è¿è¡Œåˆ†æè„šæœ¬
python3 analyze_syscalls.py

# ğŸ”¥ ç”ŸæˆperfæŠ¥å‘Š
echo "ğŸ“Š ç”Ÿæˆperfåˆ†ææŠ¥å‘Š..."
if [ -f "jvm_perf.data" ]; then
    perf report -i jvm_perf.data --stdio > perf_report.txt
    perf script -i jvm_perf.data > perf_script.txt
fi

# ğŸ”¥ åˆ†æå†…å­˜æ˜ å°„å˜åŒ–
echo "ğŸ—ºï¸  åˆ†æå†…å­˜æ˜ å°„å˜åŒ–..."
cat > analyze_memory_maps.py << 'EOF'
#!/usr/bin/env python3
import os
import re
from glob import glob

def analyze_memory_maps():
    """åˆ†æå†…å­˜æ˜ å°„å˜åŒ–"""
    
    map_files = sorted(glob('memory_maps/maps_*.txt'))
    
    if not map_files:
        print("æ²¡æœ‰æ‰¾åˆ°å†…å­˜æ˜ å°„æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(map_files)} ä¸ªå†…å­˜æ˜ å°„å¿«ç…§")
    
    # åˆ†æç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªæ˜ å°„
    first_map = map_files[0]
    last_map = map_files[-1]
    
    def parse_maps_file(filename):
        regions = []
        total_size = 0
        
        try:
            with open(filename, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        parts = line.split()
                        if len(parts) >= 6:
                            addr_range = parts[0]
                            perms = parts[1]
                            offset = parts[2]
                            dev = parts[3]
                            inode = parts[4]
                            pathname = ' '.join(parts[5:]) if len(parts) > 5 else ''
                            
                            # è®¡ç®—å¤§å°
                            start, end = addr_range.split('-')
                            size = int(end, 16) - int(start, 16)
                            total_size += size
                            
                            regions.append({
                                'start': start,
                                'end': end,
                                'size': size,
                                'perms': perms,
                                'pathname': pathname
                            })
        except FileNotFoundError:
            pass
        
        return regions, total_size
    
    first_regions, first_total = parse_maps_file(first_map)
    last_regions, last_total = parse_maps_file(last_map)
    
    print(f"\nåˆå§‹å†…å­˜æ˜ å°„: {len(first_regions)} ä¸ªåŒºåŸŸ, æ€»å¤§å°: {first_total / 1024 / 1024:.1f} MB")
    print(f"æœ€ç»ˆå†…å­˜æ˜ å°„: {len(last_regions)} ä¸ªåŒºåŸŸ, æ€»å¤§å°: {last_total / 1024 / 1024:.1f} MB")
    print(f"å†…å­˜å¢é•¿: {(last_total - first_total) / 1024 / 1024:.1f} MB")
    
    # æŸ¥æ‰¾å¤§å†…å­˜åŒºåŸŸ
    print(f"\nğŸ” å¤§å†…å­˜åŒºåŸŸ (>100MB):")
    for region in last_regions:
        if region['size'] > 100 * 1024 * 1024:
            print(f"  {region['start']}-{region['end']}: {region['size'] / 1024 / 1024:.1f} MB ({region['pathname']})")

if __name__ == '__main__':
    analyze_memory_maps()
EOF

python3 analyze_memory_maps.py

# ğŸ”¥ æ¸…ç†åˆ†æè„šæœ¬
rm -f analyze_syscalls.py analyze_memory_maps.py

echo ""
echo "âœ… JVMåˆå§‹åŒ–ç³»ç»Ÿè°ƒç”¨è¿½è¸ªå®Œæˆ"
echo "ğŸ“ åˆ†æç»“æœä¿å­˜åœ¨: $(pwd)"
echo "ğŸ“Š ä¸»è¦æ–‡ä»¶:"
echo "  - syscall_analysis_report.json  (ç³»ç»Ÿè°ƒç”¨åˆ†ææŠ¥å‘Š)"
echo "  - process_stats.csv            (è¿›ç¨‹çŠ¶æ€ç»Ÿè®¡)"
echo "  - perf_report.txt              (æ€§èƒ½åˆ†ææŠ¥å‘Š)"
echo "  - memory_maps/                 (å†…å­˜æ˜ å°„å¿«ç…§)"
echo "  - *_syscalls.log               (å„ç±»ç³»ç»Ÿè°ƒç”¨æ—¥å¿—)"
```

---

## ğŸ¯ æ€»ç»“ï¼šæç»†è‡´æ€§èƒ½å‰–æå·¥å…·çš„ä»·å€¼

### ğŸ” å·¥å…·ç‰¹è‰²

1. **çº³ç§’çº§ç²¾åº¦**ï¼š
   - ä½¿ç”¨é«˜ç²¾åº¦æ—¶é’Ÿè·å–çº³ç§’çº§æ—¶é—´æˆ³
   - æ ¡å‡†è®¡æ—¶å™¨å¼€é”€ï¼Œç¡®ä¿æµ‹é‡ç²¾åº¦
   - å®æ—¶ç›‘æ§è¿›ç¨‹çŠ¶æ€å˜åŒ–

2. **å¤šç»´åº¦ç›‘æ§**ï¼š
   - æ—¶åºåˆ†æï¼šåˆå§‹åŒ–å„é˜¶æ®µè€—æ—¶
   - å†…å­˜åˆ†æï¼šRSS/VSZå˜åŒ–è¶‹åŠ¿
   - CPUåˆ†æï¼šæ€§èƒ½è®¡æ•°å™¨ç»Ÿè®¡
   - ç³»ç»Ÿè°ƒç”¨ï¼šmmap/munmapå®Œæ•´è¿½è¸ª

3. **å¯è§†åŒ–æŠ¥å‘Š**ï¼š
   - è‡ªåŠ¨ç”Ÿæˆæ€§èƒ½å›¾è¡¨
   - è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
   - æä¾›ä¼˜åŒ–å»ºè®®

4. **ä¸“ä¸šçº§è°ƒè¯•**ï¼š
   - GDBè„šæœ¬æ”¯æŒæ–­ç‚¹è¿½è¸ª
   - å½©è‰²è¾“å‡ºå’Œæ™ºèƒ½åˆ†æ
   - å†…å­˜å¸ƒå±€å¯è§†åŒ–

### ğŸš€ åº”ç”¨ä»·å€¼

1. **æ€§èƒ½è°ƒä¼˜**ï¼š
   - ç²¾ç¡®è¯†åˆ«åˆå§‹åŒ–ç“¶é¢ˆ
   - é‡åŒ–ä¼˜åŒ–æ•ˆæœ
   - æŒ‡å¯¼å‚æ•°è°ƒæ•´

2. **é—®é¢˜è¯Šæ–­**ï¼š
   - è¿½è¸ªå¼‚å¸¸è¡Œä¸º
   - åˆ†æå†…å­˜æ³„æ¼
   - å®šä½ç³»ç»Ÿè°ƒç”¨é—®é¢˜

3. **ç ”ç©¶åˆ†æ**ï¼š
   - æ·±å…¥ç†è§£JVMå†…éƒ¨æœºåˆ¶
   - éªŒè¯ç†è®ºåˆ†æ
   - æ”¯æŒå­¦æœ¯ç ”ç©¶

è¿™å¥—æç»†è‡´çš„æ€§èƒ½å‰–æå·¥å…·ä¸ºJVMæ€§èƒ½åˆ†ææä¾›äº†ä¸“ä¸šçº§çš„è§£å†³æ–¹æ¡ˆï¼

<function_calls>
<invoke name="todo_write">
<parameter name="merge">true